{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d88339ea",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Module-Number/Introduction-to-images\" data-toc-modified-id=\"Module-Number/Introduction-to-images-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Module Number/Introduction to images</a></span><ul class=\"toc-item\"><li><span><a href=\"#Training-objectives\" data-toc-modified-id=\"Training-objectives-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Training objectives</a></span></li></ul></li><li><span><a href=\"#What-shall-we-do-with-our-images?\" data-toc-modified-id=\"What-shall-we-do-with-our-images?-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>What shall we do with our images?</a></span><ul class=\"toc-item\"><li><span><a href=\"#You-have-data...\" data-toc-modified-id=\"You-have-data...-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>You have data...</a></span><ul class=\"toc-item\"><li><span><a href=\"#Important-questions\" data-toc-modified-id=\"Important-questions-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Important questions</a></span></li><li><span><a href=\"#Which-information-do-you-expect-from-the-data\" data-toc-modified-id=\"Which-information-do-you-expect-from-the-data-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Which information do you expect from the data</a></span></li></ul></li><li><span><a href=\"#Measurements-are-rarely-perfect\" data-toc-modified-id=\"Measurements-are-rarely-perfect-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Measurements are rarely perfect</a></span></li><li><span><a href=\"#Questions\" data-toc-modified-id=\"Questions-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Questions</a></span></li></ul></li><li><span><a href=\"#Images\" data-toc-modified-id=\"Images-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Images</a></span><ul class=\"toc-item\"><li><span><a href=\"#Define-an-image\" data-toc-modified-id=\"Define-an-image-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Define an image</a></span><ul class=\"toc-item\"><li><span><a href=\"#What-is-an-image?\" data-toc-modified-id=\"What-is-an-image?-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>What is an image?</a></span></li><li><span><a href=\"#Image-sampling\" data-toc-modified-id=\"Image-sampling-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Image sampling</a></span></li><li><span><a href=\"#Different-types-of-images\" data-toc-modified-id=\"Different-types-of-images-3.1.3\"><span class=\"toc-item-num\">3.1.3&nbsp;&nbsp;</span>Different types of images</a></span></li></ul></li><li><span><a href=\"#Pixel-size-and-resolution\" data-toc-modified-id=\"Pixel-size-and-resolution-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Pixel size and resolution</a></span><ul class=\"toc-item\"><li><span><a href=\"#Pixel-size\" data-toc-modified-id=\"Pixel-size-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Pixel size</a></span></li><li><span><a href=\"#Resolution\" data-toc-modified-id=\"Resolution-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Resolution</a></span></li><li><span><a href=\"#Demonstrating-different-pixel-sizes\" data-toc-modified-id=\"Demonstrating-different-pixel-sizes-3.2.3\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>Demonstrating different pixel sizes</a></span></li><li><span><a href=\"#Edges-at-different-resolutions-and-pixel-sizes\" data-toc-modified-id=\"Edges-at-different-resolutions-and-pixel-sizes-3.2.4\"><span class=\"toc-item-num\">3.2.4&nbsp;&nbsp;</span>Edges at different resolutions and pixel sizes</a></span></li></ul></li><li><span><a href=\"#Image-intensity\" data-toc-modified-id=\"Image-intensity-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Image intensity</a></span><ul class=\"toc-item\"><li><span><a href=\"#How-many-bits-are-needed?\" data-toc-modified-id=\"How-many-bits-are-needed?-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>How many bits are needed?</a></span></li><li><span><a href=\"#The-histogram\" data-toc-modified-id=\"The-histogram-3.3.2\"><span class=\"toc-item-num\">3.3.2&nbsp;&nbsp;</span>The histogram</a></span></li><li><span><a href=\"#Details-of-the-histogram\" data-toc-modified-id=\"Details-of-the-histogram-3.3.3\"><span class=\"toc-item-num\">3.3.3&nbsp;&nbsp;</span>Details of the histogram</a></span></li><li><span><a href=\"#Histogram-examples\" data-toc-modified-id=\"Histogram-examples-3.3.4\"><span class=\"toc-item-num\">3.3.4&nbsp;&nbsp;</span>Histogram examples</a></span></li></ul></li><li><span><a href=\"#Visualizing-gray-levels\" data-toc-modified-id=\"Visualizing-gray-levels-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Visualizing gray levels</a></span><ul class=\"toc-item\"><li><span><a href=\"#Using-pseudo-colormaps\" data-toc-modified-id=\"Using-pseudo-colormaps-3.4.1\"><span class=\"toc-item-num\">3.4.1&nbsp;&nbsp;</span>Using pseudo colormaps</a></span></li><li><span><a href=\"#Brightness\" data-toc-modified-id=\"Brightness-3.4.2\"><span class=\"toc-item-num\">3.4.2&nbsp;&nbsp;</span>Brightness</a></span></li><li><span><a href=\"#Contrast\" data-toc-modified-id=\"Contrast-3.4.3\"><span class=\"toc-item-num\">3.4.3&nbsp;&nbsp;</span>Contrast</a></span></li></ul></li><li><span><a href=\"#Pixelwise-operations\" data-toc-modified-id=\"Pixelwise-operations-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Pixelwise operations</a></span><ul class=\"toc-item\"><li><span><a href=\"#Demonstrating-arithmetic-functions-(flat-field-normalization)\" data-toc-modified-id=\"Demonstrating-arithmetic-functions-(flat-field-normalization)-3.5.1\"><span class=\"toc-item-num\">3.5.1&nbsp;&nbsp;</span>Demonstrating arithmetic functions (flat field normalization)</a></span></li><li><span><a href=\"#Normalization-with-loops\" data-toc-modified-id=\"Normalization-with-loops-3.5.2\"><span class=\"toc-item-num\">3.5.2&nbsp;&nbsp;</span>Normalization with loops</a></span></li></ul></li><li><span><a href=\"#Questions\" data-toc-modified-id=\"Questions-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Questions</a></span></li></ul></li><li><span><a href=\"#Noise-in-images\" data-toc-modified-id=\"Noise-in-images-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Noise in images</a></span><ul class=\"toc-item\"><li><span><a href=\"#Noise-types\" data-toc-modified-id=\"Noise-types-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Noise types</a></span><ul class=\"toc-item\"><li><span><a href=\"#Noise-models---Gaussian-noise\" data-toc-modified-id=\"Noise-models---Gaussian-noise-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Noise models - Gaussian noise</a></span></li><li><span><a href=\"#Poisson-noise\" data-toc-modified-id=\"Poisson-noise-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>Poisson noise</a></span></li><li><span><a href=\"#Compare-Gaussian-and-Poisson-noise\" data-toc-modified-id=\"Compare-Gaussian-and-Poisson-noise-4.1.3\"><span class=\"toc-item-num\">4.1.3&nbsp;&nbsp;</span>Compare Gaussian and Poisson noise</a></span></li></ul></li><li><span><a href=\"#Signal-to-noise-ratio\" data-toc-modified-id=\"Signal-to-noise-ratio-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Signal to noise ratio</a></span><ul class=\"toc-item\"><li><span><a href=\"#Compute-the-SNR-in-an-image\" data-toc-modified-id=\"Compute-the-SNR-in-an-image-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>Compute the SNR in an image</a></span></li><li><span><a href=\"#Signal-to-noise-ratio-for-Poisson-noise\" data-toc-modified-id=\"Signal-to-noise-ratio-for-Poisson-noise-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>Signal to noise ratio for Poisson noise</a></span></li><li><span><a href=\"#Simulate-neutron-transmission-with-noise\" data-toc-modified-id=\"Simulate-neutron-transmission-with-noise-4.2.3\"><span class=\"toc-item-num\">4.2.3&nbsp;&nbsp;</span>Simulate neutron transmission with noise</a></span></li></ul></li><li><span><a href=\"#Questions\" data-toc-modified-id=\"Questions-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Questions</a></span></li></ul></li><li><span><a href=\"#Summary\" data-toc-modified-id=\"Summary-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Summary</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5563d0c8",
   "metadata": {
    "rise": {
     "backimage": "image2.jpg"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p style=\"font-size:2em;padding-bottom: 0.5em; font-weight: bold;\">\n",
    "E-learning course on <br / >\n",
    "Advanced Neutron Imaging\n",
    "</p> \n",
    "\n",
    "<p style=\"font-size:1.25em;padding-bottom: 0.25em;\">\n",
    "    \n",
    "# Module Number/Introduction to images\n",
    "\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size:1em;\">February 25, 2021</p>\n",
    "<br /><br />\n",
    "<p style=\"font-size:1.25em;padding-bottom: 0.25em; text-align: center;\">Anders Kaestner</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff7a7ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T16:28:20.442881Z",
     "start_time": "2022-02-07T16:27:40.008320Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from skimage.io import imread\n",
    "from scipy.ndimage import convolve\n",
    "from skimage.morphology import disk\n",
    "from skimage.transform import resize\n",
    "from itertools import product\n",
    "\n",
    "import os\n",
    "from io import StringIO\n",
    "import skimage as ski"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62639516",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training objectives\n",
    "\n",
    "- Terminal Training Objectives:\n",
    "    - Obtain an awareness that numerical methods are needed for the quantitative interpretation of images.\n",
    "    - Understand the concept of an image processing workflow.\n",
    "\n",
    "- Enabling training objectives:\n",
    "    - Understanding that the analysis objectives decide the choice of strategy and tools.\n",
    "    - Basic definitions of \n",
    "        - images\n",
    "        - gray levels\n",
    "        - visibility\n",
    "        - noise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefc5592",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What shall we do with our images?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828a384e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## You have data...\n",
    "\n",
    "Imaging experiments produce large amounts of data\n",
    "\n",
    "![Experiment data](figures/experimentdata.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6ae85a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Important questions\n",
    "\n",
    "What is the purpose of the experiment?\n",
    "\n",
    "- Qualitative visual analysis using 3D visualization\n",
    "- Sample characterization\n",
    "- Determine process parameters\n",
    "- Count and measure size of features\n",
    "- etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1367e644",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Which information do you expect from the data\n",
    "\n",
    "\n",
    "| Intensity  | Geometry |\n",
    "|:----------|:----------|\n",
    "| Material composition | Identify features |\n",
    "| Material transport   | Volume |\n",
    "| Physical quantities | Shape |\n",
    "\n",
    "The information you want to quantify affects:\n",
    "- The choice of processing method\n",
    "- The experiment strategy \n",
    "- The choice of analysis tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecd95d0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Measurements are rarely perfect\n",
    "\n",
    "<center>\n",
    "<img src=\"figures/imperfect_imaging_system.svg\" style=\"height:350px\">\n",
    "</center>\n",
    "\n",
    "Relevant features versus:\n",
    "- Resolution\n",
    "- Sample movement\n",
    "- Noise\n",
    "- Inhomogeneous contrast\n",
    "- Artefacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628f308f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Questions\n",
    "1. Why \n",
    "2. How\n",
    "3. When"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420810c8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f92bec",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Define an image\n",
    "\n",
    "### What is an image?\n",
    "\n",
    "A very abstract definition: \n",
    "- __A pairing between spatial information (position)__\n",
    "- __and some other kind of information (value).__\n",
    "\n",
    "In most cases this is a 2- or 3-dimensional position (x,y,z coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0645bd98",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Image sampling\n",
    "| The world is | The computer needs|\n",
    "|:---:|:---:|\n",
    "| Continuous    | Discrete levels |\n",
    "| No boundaries | Limited extent | "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccc1581",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "A real world observation is contious and we need to sample the information in order to bring it into the computer for storage and to perform our analysis. There are different types of sampling involved to get a digital image. \n",
    "\n",
    "Intensity \n",
    ": The continous intensity must be sampled into discrete levels represented by a number of bits\n",
    "\n",
    "Locations\n",
    ":The location in the scene must be rasterized into a grid of pixels that contain the image intensity. The size of the pixels determine the greatest spatial frequency that can be respresented in the image. The spatial sampling follows the Nyquist sampling theorem that says that you have to sample by twice as fast the highest frequency in the scene. If you sample too slow you will see aliasing effects that appear as moiree fringes in the image.   \n",
    "\n",
    "```{figure} figures/grid.pdf\n",
    "---\n",
    "scale: 75%\n",
    "---\n",
    "The real world is sampled into discrete images with limited extent.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9386a7b6",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"figures/grid.svg\" style=\"height:400px\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8269de3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Different types of images\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th><center>2D</center></th>\n",
    "        <th><center>3D</center></th>\n",
    "        <th><center>4D</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"figures/plane_10x10.svg\" style=\"height:50px\"></td>\n",
    "        <td><img src=\"figures/cube_10x10x10.svg\" style=\"height:100px\">\n",
    "            <img src=\"figures/timeseries_visualization.svg\" style=\"height:100px\">\n",
    "        </td>\n",
    "        <td><img src=\"figures/4D-images.svg\" style=\"height:100px\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Radiographs</td>\n",
    "        <td>Tomography<br/>Time-series<br/>Spectrum</td>\n",
    "        <td>Volume time series</td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d1ed41",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Pixel size and resolution \n",
    "\n",
    "It is important to distinguish between pixel size and resolution\n",
    "\n",
    "### Pixel size\n",
    "The pixel size is\n",
    "- The sample pitch between two adjacent pixels\n",
    "- The smallest area represented in the image\n",
    "\n",
    "### Resolution \n",
    "The resolution is related to the optical system\n",
    "- It is the effect of the optical transfer function of the acquisition system.\n",
    "- Should have a greater value than the pixel size.\n",
    "- Defines the smallest pixel size when you set up your acquistion conditions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9db203",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Demonstrating different pixel sizes\n",
    "What happens when we represent the same image with less pixels?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f202aec",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "In this example we downsample the image first by a factor two. This change is barely visible when we show the image, but the number of pixels have reduced by a factor four. In the second example the image is downscaled by a factor 32 and you can clearly observe how pixelated the image is. A this level of downscaling, you can only see very coarse features in the sample.\n",
    "\n",
    "Down scaling is sometimes used as a method to speed up the frame rate as it radiacally reduces the number of bytes to be transfered from the detector and also the amount of data to write on disk. You should however be careful not to down scale by a too great factor as you will loose spatial information when doing so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a09f402",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T16:28:30.347273Z",
     "start_time": "2022-02-07T16:28:29.415454Z"
    }
   },
   "outputs": [],
   "source": [
    "img=np.load('data/wood.npy');\n",
    "fig,ax = plt.subplots(1,3, figsize=[15,5])\n",
    "ax[0].imshow(img,cmap='gray'); plt.title('Original')\n",
    "\n",
    "downsize =  2; \n",
    "resized  = resize(img,(img.shape[0] // downsize, img.shape[1] // downsize))\n",
    "ax[1].imshow(resized, interpolation='None',cmap='gray'); ax[1].set_title('Downsize {0}x{0}'.format(downsize))\n",
    "\n",
    "downsize = 32; \n",
    "resized  = resize(img,(img.shape[0] // downsize, img.shape[1] // downsize))\n",
    "ax[2].imshow(resized,interpolation='None',cmap='gray'); ax[2].set_title('Downsize {0}x{0}'.format(downsize));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea35c21c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Edges at different resolutions and pixel sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49c30a0",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Finding the correct pixel size is related to the resolution of the imaging system. You can sample low resolved scenes with many pixels but then the edges will appear blurred and will essentially waste a lot data on little added value.\n",
    "\n",
    "The example below shows what an ideal edge would look like and what it mostly looks like when we acquire our images. As you can see, the \"real\" edge is represented by a smooth transition spread over several pixels.\n",
    "\n",
    "```{figure} figures/edge.pdf\n",
    "---\n",
    "scale: 75%\n",
    "---\n",
    "Examples of edges sampled with different pixel sizes.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078817ea",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"figures/edges.svg\" style=\"height:600px\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ceb732",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Image intensity\n",
    "What happens when we reduce the number of gray-levels in the image?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64143a41",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The image intensity is determined by the response function of the imaging system. In the case of neutron imaging we are talking about the transmission of the neutron beam through the sample. The transmission follows Beer-Lambert's law\n",
    "$I(x,y)=I(x,y) e^{-\\int_L \\mu(x) dx}$, this is only a simplified version. More complicated versions including the neutron energy are presented in other parts of this course.\n",
    "\n",
    "The information captured by the detector is stored in digital form with different gray level dynamics. We are often talking about 8 or 16 bit integer when we store images. This means that each pixel can represent the measured intensity with either 256 or 65565 gray levels respectively. In the example below we demonstrate what happens when only very few gray levels are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d19f65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T16:28:33.129468Z",
     "start_time": "2022-02-07T16:28:32.189603Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img=np.load('data/wood.npy');\n",
    "fig,ax = plt.subplots(1,3,figsize=[15,7])\n",
    "ax[0].imshow(img, cmap='gray'); plt.title('Original')\n",
    "\n",
    "levels   = 16; \n",
    "lvl = np.floor(img*levels)\n",
    "ax[1].imshow(lvl, cmap='gray'); ax[1].set_title('{0} Levels'.format(levels));\n",
    "\n",
    "levels   = 4 ; \n",
    "lvl = np.floor(img*levels)\n",
    "ax[2].imshow(lvl, cmap='gray'); ax[2].set_title('{0} Levels'.format(levels));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88becfcd",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "It is important to use as many gray levels at possible when you expose your images. The image turns patchy when you use too few levels which you can see in the example above. The patchiness reduces the precision of your evaluation, there is less margin to make estimations and decisions. The number of gray levels depend on many factors like:\n",
    "\n",
    "- Exposure time\n",
    "- Neutron flux\n",
    "- Conversion efficiency\n",
    "- Conversion rate of the detector\n",
    "- Pixel size\n",
    "\n",
    "So, it is your task to optimize your acquisition to provide well illuminated images by changing these parameters. Some are easier than others to change and contstraint are given by the type of investigation you are doing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494319a2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How many bits are needed?\n",
    "\n",
    "The number of bits you need depends on:\n",
    "- Contrast difference\n",
    "- Separate many different sample features\n",
    "- Sensitivity to rounding errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6339c1",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The table below gives you an idea how many bits you need to represent your image information. In the extreme you would only need a single bit per pixel (8 pixels per byte) to represent a bi-level image from a segmentation. The other extreme would be to use double precision floating point that requires 64 bits (8 bytes) per pixels. Double precision is rarely needed and single precision is mostly sufficient which saves you memory. Saving memory is in particular important when you work with 3D images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cbfd40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-06T17:21:57.808840Z",
     "start_time": "2022-02-06T17:21:57.801994Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<span style=\"font-size:1.5em;\">\n",
    "\n",
    "| Few bits | Many bits | Floating point |\n",
    "|:----------|:-----------|:----------------|\n",
    "|High contrast<br/>Clean images<br/>Segmented data|Low contrast<br/>Noisy images<br/>Gradual changes|High intensity dynamics<br/>Quantification to physical properties<br/>In algorithms|\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8531f1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The histogram\n",
    "\n",
    "The histogram is a statistical tool to show frequency of each graylevel in the image. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ae86fb",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "It is essentially a plot where the you count how many times each gray level appears in the image. For a 16-bit image this would result 65565 points. This is far too detailed therefore it is common to use bins of several gray level to reduce the level of detail in the histogram and also improve the readability. In the example below we use 100 histogram bins which look quite reasonable for this image. Chosing the number of bins depends on the image size too. Your histogram doesn't look very useful if you have too many bins compared to the available number of pixels. You can use the piece of code below to explore what happens when you change the number of bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2aadddb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T16:28:36.050721Z",
     "start_time": "2022-02-07T16:28:35.098367Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(15,5))\n",
    "\n",
    "# Compute and show a histogram\n",
    "ax[0].hist(img.ravel(),bins=200)\n",
    "\n",
    "\n",
    "ax[0].set_xlabel('Image value'), ax[0].set_ylabel('Number of pixels')\n",
    "ax[1].imshow(img,cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382a4c30",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "It can be used for the analysis of the image as it gives you an idea which values are related to different features in the image. The histogram tells you the area covered by a give pixel value and a later section we will see how the histogram can be used to segment the images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49d871b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Details of the histogram\n",
    "Let's look att different regions in the image and their representation in the histogram.\n",
    "\n",
    "<center>\n",
    "<img src=\"figures/histogram_regions.svg\" style=\"height:400px\">\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde42215",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T07:29:21.768081Z",
     "start_time": "2022-02-04T07:29:21.762397Z"
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "```{figure} figures/histogram_regions.pdf\n",
    "---\n",
    "scale: 75%\n",
    "---\n",
    "Regions in the image connected to their position in the histogram.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b835485a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Histogram examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8401b33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T16:28:39.988909Z",
     "start_time": "2022-02-07T16:28:37.293310Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "a=plt.imread('figures/testpattern_noisy.jpg')\n",
    "b=plt.imread('figures/neutron_camera.png')\n",
    "c0=plt.imread('figures/root_slices.png')\n",
    "c1=plt.imread('figures/root_histogram.png')\n",
    "\n",
    "fig,ax=plt.subplots(2,3,figsize=(15,8))\n",
    "ax=ax.ravel()\n",
    "\n",
    "ax[0].imshow(a,cmap='gray')\n",
    "ax[0].set_xticks([]);ax[0].set_yticks([])\n",
    "ax[0].set_title('Noisy bi-level image')\n",
    "ax[3].hist(a.ravel(),bins=100)\n",
    "ax[1].imshow(b,cmap='gray')\n",
    "ax[1].set_title('Neutron image')\n",
    "ax[1].set_xticks([]);ax[1].set_yticks([])\n",
    "ax[4].hist(b.ravel(),bins=100)\n",
    "ax[2].imshow(c0)\n",
    "ax[2].set_title('Bivariate data')\n",
    "ax[2].axis('off')\n",
    "ax[5].imshow(c1)\n",
    "ax[5].axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c77661",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Visualizing gray levels\n",
    "\n",
    "The human eye is not able to resolve many intensity levels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ff878b",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "In this example we demonstrate how easy or hard it can be to perceive contrast differences in an image with different number of gray levels. How well you can see the differences depends on one hand on how well your eye can resolve the contrast difference, but there are also technical issues related to how well you can see the changes. E.g. how well your screen can display the changes and even the ambient light in the room you are working in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce1a5ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T16:28:40.726309Z",
     "start_time": "2022-02-07T16:28:40.010521Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "xlin = np.linspace(0,255, 256)\n",
    "xx, yy = np.meshgrid(xlin, xlin)\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize = (15, 5))\n",
    "n=32; ax[0].imshow(np.floor(xx/n), interpolation='None', cmap = 'gray');  ax[0].set_title('{0} levels'.format(256//n))\n",
    "n=8;  ax[1].imshow(np.floor(xx/n), interpolation='None', cmap = 'gray');  ax[1].set_title('{0} levels'.format(256//n))\n",
    "n=1;  ax[2].imshow(np.floor(xx/n), interpolation='None', cmap = 'gray');  ax[2].set_title('{0} levels'.format(256//n));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7bb26b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Using pseudo colormaps\n",
    "\n",
    "The image intensity is mostly only represented by a scalar by a gray level. Which is makes it hard to see subtle changes in intensity. Colormaps can help here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa85800f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T16:28:41.867507Z",
     "start_time": "2022-02-07T16:28:40.729897Z"
    }
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,3,figsize=(15,5))\n",
    "ax[0].imshow(img,cmap='gray');    ax[0].set_title('Gray')\n",
    "ax[1].imshow(img,cmap='viridis'); ax[1].set_title('Viridis')\n",
    "ax[2].imshow(img,cmap='hot');     ax[2].set_title('Hot');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0947e5c",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Colormaps are only used for the visulization making it possible to better visualize and highlight features in the image. They can however also be misleading if you chose the wrong colormap. The interpretation of the image is in particular hard when you start manipulating the colormap. In this way it is even posible to \"invent\" features in the image that are not real. A typical example is that you thanks to the colormap could see a denser skin like structure near the sample boundary. It the reality this \"skin\" is only the smooth edge which is caused by low resolution of the imaging system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba555ca",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Brightness\n",
    "With image brightness, you can focus on narrow gray level intervals to better visually resolve local details.\n",
    "\n",
    "<center>\n",
    "<img src=\"figures/histogram_brightness.svg\" style=\"height:500px\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e7f7ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T19:03:40.005724Z",
     "start_time": "2022-02-04T19:03:39.993585Z"
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "```{figure} figures/histogram_brightness.pdf\n",
    "---\n",
    "scale: 75%\n",
    "---\n",
    "Narrow intensity intervals to highlight low (left) and high (right) graylevel regions.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0db50b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T18:29:28.371180Z",
     "start_time": "2022-02-04T18:29:28.368553Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Contrast\n",
    "\n",
    "Contrast controls the width of the intensity interval to use.\n",
    "\n",
    "<center>\n",
    "<img src=\"figures/histogram_contrast.svg\" style=\"height:500px\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f792776",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Contrast control is often used to define which gray levels to include when you save image to file. The image is usually represented in floating point data format after some calculations and you have to limit the interval to resolve the relevant information with many gray levels and reject outliers when you convert to 8- or 16-bit integers. \n",
    "\n",
    "The example shows a narrow interval that mostly is useful to highlight features with small difference in contrast. The example with wider interval would is set to reject the background while most of the sample is visible. This setting may be useful for presentationations and publication where you want to boost the visibility, but is not recommended if you want to use the image in further calculations. In the latter case it is important to keep as many gray levels as possible, i.e. also include the noise flucuations in the background.\n",
    "\n",
    "```{figure} figures/histogram_contrast.pdf\n",
    "---\n",
    "scale: 75%\n",
    "---\n",
    "Different image contrasts. Narrow interval to the left and wide interval to the right.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab9f4d3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Pixelwise operations\n",
    "\n",
    "Pixelwise operations apply scalar operations to each pixel.\n",
    "- Arithmetics +, -, *, /\n",
    "- Functions e.g. sin(x), exp(x), ln(x)\n",
    "\n",
    "Statistic functions\n",
    "- mean, standard deviation\n",
    "- min, max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d759279e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T17:24:41.128891Z",
     "start_time": "2022-02-05T17:24:41.120582Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Demonstrating arithmetic functions (flat field normalization)\n",
    "\n",
    "$$normed = \\frac{img-dc}{ob-dc}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663ad581",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T16:28:43.095955Z",
     "start_time": "2022-02-07T16:28:41.881010Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = plt.imread('data/wood_0000.tif')\n",
    "ob  = plt.imread('data/ob_0000.tif')\n",
    "dc  = plt.imread('data/dc_0000.tif')\n",
    "\n",
    "normed = (img-dc)/(ob-dc)\n",
    "\n",
    "fig,ax = plt.subplots(1,4,figsize=(15,4))\n",
    "ax[0].imshow(img,    cmap='gray'); ax[0].set_title('Sample image')\n",
    "ax[1].imshow(ob,     cmap='gray'); ax[1].set_title('Open beam image')\n",
    "ax[2].imshow(dc,     cmap='gray'); ax[2].set_title('Dark current image')\n",
    "ax[3].imshow(normed, cmap='gray'); ax[3].set_title('Normalized image');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22926f81",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Normalization with loops\n",
    "Pixel wise operations can also be implemented using loops. This results in more complicated code and is mostly less efficent in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d04a43b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T16:28:44.647901Z",
     "start_time": "2022-02-07T16:28:43.100436Z"
    }
   },
   "outputs": [],
   "source": [
    "normed = np.zeros(img.shape)\n",
    "\n",
    "for r in range(img.shape[0]):\n",
    "    for c in range(img.shape[1]):\n",
    "        normed[r,c]=(img[r,c]-dc[r,c])/(ob[r,c]-dc[r,c])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cb3910",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Questions\n",
    "1. How many gray levels can the human eye percieve? Try to find your limit using the code.\n",
    "2. What does the histogram tell you about an image?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5a1310",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Noise in images\n",
    "\n",
    "Noise is in very general terms for the unwanted information in a signal. \n",
    "\n",
    "More specifically, we are talking about random contributions that obscure the image information we are interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2093fd",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Noise types\n",
    "Noise can have many different characteristics. In general, it is driven by a random distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a22ed7a",
   "metadata": {},
   "source": [
    "- Spatially uncorrelated noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b17c11b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T17:54:58.999724Z",
     "start_time": "2022-02-05T17:54:58.993054Z"
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "With spatially uncorrelated noise each pixel has a random value which is independend of the pixel neighborhood. This is also the easiest noise type to simulate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e99ecb7",
   "metadata": {},
   "source": [
    "- Event noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32ea8ef",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The even noise has a random activation function that triggers the event of each pixel with some probabilty. This noise type produces spots randomly distributed over the image. The spots may also have a randomw intensity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344f0e5c",
   "metadata": {},
   "source": [
    "- Stuctured noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc97eab8",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The structured noise depends on the values of the pixel neighborhood and is thus spatially correlated. It is mostly driven by an uncorrelated noise source which is blurred by a weighted combination of the neighborhood.\n",
    "\n",
    "The figure below shows examples of the three noise types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816fdac1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T16:28:47.454951Z",
     "start_time": "2022-02-07T16:28:46.972507Z"
    },
    "hide_input": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[12,4]);\n",
    "plt.suptitle('Noise examples')\n",
    "plt.subplot(1,3,1);plt.imshow(np.random.normal(0,1,[100,100])); plt.title('Gaussian');plt.axis('off');\n",
    "plt.subplot(1,3,2);plt.imshow(0.90<np.random.uniform(0,1,size=[100,100]),cmap='gray'); plt.title(\"Salt and pepper\"),plt.axis('off');\n",
    "plt.subplot(1,3,3);plt.imshow(ski.filters.gaussian(np.random.normal(0,1,size=[100,100]),sigma=1),cmap='gray'); plt.title(\"Structured\"),plt.axis('off');\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30853f1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Noise models - Gaussian noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3f82f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T18:05:31.998381Z",
     "start_time": "2022-02-05T18:05:31.987175Z"
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Gaussian noise is the most common random distribution used. All other distributions asymptotically converges towards the Gaussian distribution thanks to the [central limit theorem](https://en.wikipedia.org/wiki/Central_limit_theorem). The Gaussian noise is an easy distribution to work with when you derive signal processing models. This is also the reason why it is so popular to use this model also for non-Gaussian noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e245663",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* Additive\n",
    "* Easy to model \n",
    "* Law of large numbers\n",
    "\n",
    "__Distribution function__\n",
    "\n",
    "$$n(x)=\\frac{1}{\\sqrt{2\\pi\\sigma}}\\exp{-\\left(\\frac{x-\\mu}{2\\sigma}\\right)^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013c6ac5",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Below you see plots of the Gaussian distribution with different values for $\\mu$ and $\\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642ad4d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T16:28:50.215806Z",
     "start_time": "2022-02-07T16:28:49.106968Z"
    },
    "hide_input": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "rv = norm(loc = -1., scale = 1.0);rv1 = norm(loc = 0., scale = 2.0); rv2 = norm(loc = 2., scale = 3.0)\n",
    "x = np.arange(-10, 10, .1)\n",
    "plt.figure(figsize=(5,4))\n",
    "#plot the pdfs of these normal distributions \n",
    "plt.plot(x, rv.pdf(x),label='$\\mu$=-1, $\\sigma$=1')\n",
    "plt.plot(x, rv1.pdf(x),label='$\\mu$=0, $\\sigma$=2') \n",
    "plt.plot(x, rv2.pdf(x),label='$\\mu$=2, $\\sigma$=3')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03ac1b3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Poisson noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7581a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T18:07:29.161897Z",
     "start_time": "2022-02-05T18:07:29.150115Z"
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The Poisson noise is the central noise model for event counting processes. It is thus the type of noise you see in imaging as the detectors in some sense is counting the number of particles arriving at the detector, e.g. photons or neutrons. This noise distribution changes shape with increasing number of particles; the distribution is clearly asymmetric for few particles while it takes a Gaussian shape when many particles are counted. It is also multiplicative in contrast to the Gaussian noise. This is in other words the noise distribution you need to use if you want to model image noise correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3333b6",
   "metadata": {},
   "source": [
    "* Multiplicative\n",
    "* Physically correct for event counting\n",
    "\n",
    "__Distribition function__ \n",
    "\n",
    "$$p(x)=\\frac{\\lambda^{k}}{k!} e^{-\\lambda\\,x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5e8ce6",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The plot below show a poisson distribtion for $\\lambda$=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4021ef51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T16:28:51.558350Z",
     "start_time": "2022-02-07T16:28:51.298993Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import poisson\n",
    "mu=3\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "x = np.arange(poisson.ppf(0.01, mu),              poisson.ppf(0.999, mu))\n",
    "ax.plot(x, poisson.pmf(x, mu), 'bo', ms=8, label='poisson pmf')\n",
    "ax.vlines(x, 0, poisson.pmf(x, mu), colors='b', lw=5, alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b063fc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Compare Gaussian and Poisson noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e0e507",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Now, let's compare relaizations of Gaussian and Poisson noise overlaid on a sine curve. The important thing to observe is that the noise amplitude is independent of the signal value and constant for the Gaussian noise. For Poisson noise it is very different. The noise amplitude changes with the signal values. Higher signal strength also produces greater noise amplitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d257a273",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T16:28:52.818059Z",
     "start_time": "2022-02-07T16:28:52.376169Z"
    },
    "hide_input": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[15,8])\n",
    "x=np.linspace(0,2*np.pi,100); \n",
    "y=10*np.sin(x)+11; ng=np.random.normal(0,1,size=len(x)); npoi = np.random.poisson(y);\n",
    "plt.subplot(2,2,1); plt.plot(x,y+ng);plt.plot(x,y); plt.axis('off');plt.title('Gaussian'); plt.subplot(2,2,3);plt.plot(x,ng);plt.axis('off');\n",
    "plt.subplot(2,2,2); plt.plot(x,npoi);plt.plot(x,y); plt.axis('off');plt.title('Poisson'); plt.subplot(2,2,4);plt.plot(x,npoi-y);plt.axis('off');\n",
    "plt.suptitle('Samples of two distributions');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8664e22c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Signal to noise ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9ff680",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "It is important to know how strong the noise is compared to the signal in order to decide how to proceed with the analysis. Therefore, we need a metric to quantify the noise. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e23d36b",
   "metadata": {},
   "source": [
    "The Signal to noise ratio measures the noise strengh in a signal\n",
    "\n",
    "__Definition__\n",
    "\n",
    "$$SNR=\\frac{mean(f)}{stddev(f)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2160a044",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Sometimes the term contrast to noise ratio is also used. This means that you measure the intensity difference in between two relevant features and divide this by the noise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9180e7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Compute the SNR in an image\n",
    "To compute the SNR you have to \n",
    "1. Select a region of the image with near constant intensity (not considering the noise)\n",
    "2. Compute average intensity and standard deviation\n",
    "3. Compute the SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47de5434",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T16:28:54.933190Z",
     "start_time": "2022-02-07T16:28:54.588540Z"
    },
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = np.load('data/wood.npy')\n",
    "plt.imshow(img, cmap='gray')\n",
    "# Create a Rectangle patch\n",
    "rect = patches.Rectangle((50, 50), 50, 50, linewidth=1, edgecolor='r', facecolor='none')\n",
    "plt.gca().add_patch(rect);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5140efd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T16:28:54.988737Z",
     "start_time": "2022-02-07T16:28:54.982603Z"
    }
   },
   "outputs": [],
   "source": [
    "avg = np.mean(img[50:100,50:100])\n",
    "std = np.std(img[50:100,50:100])\n",
    "SNR = avg/std\n",
    "print('avg={0:0.4f}, std={1:0.4f} => SNR=avg/std={2:0.2f}'.format(avg,std,SNR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c5a40f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Signal to noise ratio for Poisson noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef96e56",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The SNR of poisson noise is particularly easy to compute because $E[x]=v[x]$. This means that the SNR is proportional to the square root of the number of particles. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90292847",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T18:16:07.873295Z",
     "start_time": "2022-02-05T18:16:07.862917Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- For a Poisson distribution the SNR is :\n",
    "\n",
    "$$SNR=\\frac{E[x]}{s[x]}\\sim\\frac{N}{\\sqrt{N}}=\\sqrt{N}$$\n",
    "\n",
    "- $N$ is the number of particles $\\sim$ exposure time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86609808",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T18:14:56.564200Z",
     "start_time": "2022-02-05T18:14:56.548819Z"
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "where _N_ is the number of captured particles. The figure below shows two neutron images acquired at 0.1s and 10s respectively. The plot shows the signal to noise ratio obtained for different exposure times.\n",
    "\n",
    "The signal to noise ratio can be improved by increasing the number of neutrons per pixel. This can be achived through increasing\n",
    "- Neutron flux - this is usually relatively hard as the neutron sources operate with the parameters it is designed for. There is a posibilty by changing the neutron aperture, but has an impact of the beam quality.\n",
    "- Exposure time - the exposure time can be increased but in the end there is a limitation on how much this can be used. Beam time is limited which means the experiment must be finished in a given time. There is also an upper limit on the exposure time defined by the observed sample or process when it changes over time. Too long exposure times will result in motion artefacts.\n",
    "- Pixel size - increasing the pixel size means that neutrons are collected over a greater area and thus more neutrons are captured during the exposure. The limit on how much you can increase the pixel size is defined by the smallest features you want to detect.\n",
    "- Detector material and thickness - the number of captured neutrons depends on the scintillator material and how thick it is. The thickness does however have an impact on the resolution. Therefore scintillator thickness and pixel size often increase in parallel as there is no point in oversampling a smooth signal to much.\n",
    "\n",
    "In the end, there are many parameters that combined results in the SNR you obtain. These parameters are tuned to match the experiment conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8916b7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T16:28:57.723447Z",
     "start_time": "2022-02-07T16:28:56.888905Z"
    },
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exptime=np.array([50,100,200,500,1000,2000,5000,10000])\n",
    "snr = np.array([ 8.45949767, 11.40011621, 16.38118766, 21.12056507, 31.09116641,40.65323123, 55.60833117, 68.21108979]);\n",
    "\n",
    "marker_style = dict(color='cornflowerblue', linestyle='-', marker='o',markersize=10, markerfacecoloralt='gray');\n",
    "\n",
    "fig,ax = plt.subplots(1,3,figsize=(15,5)) \n",
    "\n",
    "ax[1].plot(exptime/1000,snr, **marker_style);\n",
    "ax[1].set_xlabel('Exposure time [s]');\n",
    "ax[1].set_ylabel('SNR [1]')\n",
    "img50ms=plt.imread('data/tower_50ms.png'); \n",
    "img10000ms=plt.imread('data/tower_10000ms.png');\n",
    "\n",
    "ax[0].imshow(img50ms,cmap='gray');    ax[0].set_title('50ms'); \n",
    "ax[2].imshow(img10000ms, cmap='gray'); ax[2].set_title('10s');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6249e15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T18:31:32.341643Z",
     "start_time": "2022-02-05T18:31:32.335173Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Simulate neutron transmission with noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed1e8c0",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "In this example we simulate the noise in an image base on the number of detected neutrons. This is an incomplete model of the imaging system. It does not include detector efficiency and blurring. Still, it gives you an idea of how the exposure time, pixel size and neutron flux have an impact on the signal to noise ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8d94f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T16:28:58.295699Z",
     "start_time": "2022-02-07T16:28:58.262239Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "def simulateTransmission(neutrons=100,scalex=20,scaley=50) :\n",
    "    img=np.array([[  1,   1,   1,   1,   1,   1,   1,   1,   1,  1,    1,   1, 1.0],\n",
    "                  [1.0, 1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1, 1.0, 1.0],\n",
    "                  [  1,   1,   1,   1,   1,   1,   1,   1,   1,  1,    1,   1, 1.0]])\n",
    "    \n",
    "    img=np.repeat(img,scalex,axis=1)\n",
    "    img=np.repeat(img,scaley,axis=0)\n",
    "    img=neutrons*img\n",
    "    \n",
    "    img=np.random.poisson(img)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fa1ade",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T16:28:59.577178Z",
     "start_time": "2022-02-07T16:28:58.754444Z"
    }
   },
   "outputs": [],
   "source": [
    "expTime  = 10    # s\n",
    "pixSize  = 100  # um\n",
    "flux     = 1e7  # neutrons/cm2/s\n",
    "\n",
    "neutrons = expTime * (pixSize * 1e-4) ** 2 * flux\n",
    "img = simulateTransmission(neutrons=neutrons) # A 'hidden' function in the notebook\n",
    "\n",
    "m   = img[55:80].mean(axis=0)\n",
    "s   = img[55:80].std(axis=0)\n",
    "SNR = m/s\n",
    "\n",
    "# Visualization\n",
    "fig, ax = plt.subplots(1,3,figsize=(16,3))\n",
    "ax[0].imshow(img, interpolation='None',cmap='gray')\n",
    "ax[0].set_title('Simulated image ({0:0.0f} neutrons/pixel)'.format(neutrons))\n",
    "ax[1].plot(m,label='Average')\n",
    "ax[1].fill_between(x=range(img.shape[1]), y1=m-s,y2=m+s,color='r',alpha=0.3,label='Standard deviation');\n",
    "ax[1].legend(); ax[1].set_xlabel('Pixel position'); ax[1].set_ylabel('Pixel intensity [a.u.]'); ax[1].set_title('Profile')\n",
    "ax[2].plot(SNR);\n",
    "ax[2].set_xlabel('Pixel position'); ax[2].set_ylabel('SNR [1]'); ax[2].set_title('Signal to Noise ratio');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0660283",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Questions\n",
    "\n",
    "1. Why is the understanding of noise and its orgin relevant to neutron imaging?\n",
    "2. Can you improve the signal to noise ratio at experiment time? \n",
    "    - What are the easiest methods to change the SNR?\n",
    "    - What is the hardest way to improve the SNR?\n",
    "    - Why would you decide to accept a lower SNR?\n",
    "3. How many more neutrons would you need to double the SNR?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec48de84",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Summary \n",
    "\n",
    "In this lecture you learned about:\n",
    "1. Images and pixels.\n",
    "2. Gray level dynamics and how to visualize them.\n",
    "2. The histogram.\n",
    "3. Noise and how to improve signal to noise ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded45797",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "rise": {
   "autolaunch": true,
   "backimage": "image1.png",
   "enable_chalkboard": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
